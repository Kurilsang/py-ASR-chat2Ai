"""
Whisper ASRè¯­éŸ³è¯†åˆ«æœåŠ¡
åŸºäºOpenAI Whisperæ¨¡å‹çš„é«˜ç²¾åº¦è¯­éŸ³è¯†åˆ«
æ”¯æŒæœ¬åœ°æ¨¡å‹å’ŒAPIè°ƒç”¨ä¸¤ç§æ¨¡å¼
"""

import os
import tempfile
import wave
import numpy as np
from typing import Optional, Union
import speech_recognition as sr
from utils.config_manager import ConfigManager


class WhisperASRService:
    """åŸºäºOpenAI Whisperçš„ASRè¯­éŸ³è¯†åˆ«æœåŠ¡"""
    
    def __init__(self, config_manager: ConfigManager):
        """
        åˆå§‹åŒ–Whisper ASRæœåŠ¡
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨
        """
        self.config = config_manager
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        
        # è·å–é…ç½®
        self.model_size = self.config.get_string('WHISPER_SETTINGS', 'model_size', 'base')
        self.use_api = self.config.get_bool('WHISPER_SETTINGS', 'use_api', False)
        self.api_key = self.config.get_string('WHISPER_SETTINGS', 'api_key', '')
        self.language = self.config.get_string('WHISPER_SETTINGS', 'language', 'zh')
        self.device = self.config.get_string('WHISPER_SETTINGS', 'device', 'auto')
        
        # åˆå§‹åŒ–Whisper
        self.whisper_model = None
        self._initialize_whisper()
        
        # è°ƒæ•´ç¯å¢ƒå™ªéŸ³
        self._adjust_ambient_noise()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.usage_stats = {
            'total_recognitions': 0,
            'successful_recognitions': 0,
            'api_calls': 0,
            'local_calls': 0,
            'avg_confidence': 0.0
        }
    
    def _initialize_whisper(self):
        """åˆå§‹åŒ–Whisperæ¨¡å‹"""
        try:
            if self.use_api and self.api_key:
                print("ğŸ”§ é…ç½®Whisper APIæ¨¡å¼...")
                # è®¾ç½®OpenAI API Key
                os.environ['OPENAI_API_KEY'] = self.api_key
                print("âœ… Whisper APIé…ç½®å®Œæˆ")
            else:
                print(f"ğŸ”§ åŠ è½½Whisperæœ¬åœ°æ¨¡å‹: {self.model_size}")
                import whisper
                
                # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
                if self.device == 'auto':
                    import torch
                    device = 'cuda' if torch.cuda.is_available() else 'cpu'
                    print(f"ğŸ”§ è‡ªåŠ¨é€‰æ‹©è®¾å¤‡: {device}")
                else:
                    device = self.device
                
                self.whisper_model = whisper.load_model(self.model_size, device=device)
                print(f"âœ… Whisperæœ¬åœ°æ¨¡å‹åŠ è½½å®Œæˆ (æ¨¡å‹: {self.model_size}, è®¾å¤‡: {device})")
                
        except ImportError:
            print("âŒ Whisperåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openai-whisper")
            raise
        except Exception as e:
            print(f"âŒ Whisperåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _adjust_ambient_noise(self):
        """è°ƒæ•´ç¯å¢ƒå™ªéŸ³"""
        print("ğŸ”§ æ­£åœ¨è°ƒæ•´ç¯å¢ƒå™ªéŸ³ï¼Œè¯·ä¿æŒå®‰é™...")
        try:
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=2)
            print("âœ… ç¯å¢ƒå™ªéŸ³è°ƒæ•´å®Œæˆï¼")
        except Exception as e:
            print(f"âš ï¸ ç¯å¢ƒå™ªéŸ³è°ƒæ•´å¤±è´¥ï¼š{e}")
    
    def recognize_chinese(self, audio_data: sr.AudioData) -> Optional[str]:
        """
        ä½¿ç”¨Whisperè¯†åˆ«ä¸­æ–‡è¯­éŸ³
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬ï¼Œå¦‚æœè¯†åˆ«å¤±è´¥è¿”å›None
        """
        return self._recognize_with_whisper(audio_data, language='zh')
    
    def recognize_english(self, audio_data: sr.AudioData) -> Optional[str]:
        """
        ä½¿ç”¨Whisperè¯†åˆ«è‹±æ–‡è¯­éŸ³
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬ï¼Œå¦‚æœè¯†åˆ«å¤±è´¥è¿”å›None
        """
        return self._recognize_with_whisper(audio_data, language='en')
    
    def recognize_auto(self, audio_data: sr.AudioData) -> Optional[str]:
        """
        ä½¿ç”¨Whisperè‡ªåŠ¨è¯†åˆ«è¯­éŸ³ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼‰
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬ï¼Œå¦‚æœè¯†åˆ«å¤±è´¥è¿”å›None
        """
        return self._recognize_with_whisper(audio_data, language=None)
    
    def _recognize_with_whisper(self, audio_data: sr.AudioData, language: Optional[str] = None) -> Optional[str]:
        """
        ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            language: æŒ‡å®šè¯­è¨€ä»£ç ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
            
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬
        """
        self.usage_stats['total_recognitions'] += 1
        
        try:
            if self.use_api and self.api_key:
                return self._recognize_with_api(audio_data, language)
            else:
                return self._recognize_with_local_model(audio_data, language)
                
        except Exception as e:
            print(f"âŒ Whisperè¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def _recognize_with_api(self, audio_data: sr.AudioData, language: Optional[str]) -> Optional[str]:
        """ä½¿ç”¨Whisper APIè¿›è¡Œè¯†åˆ«"""
        try:
            print("ğŸŒ æ­£åœ¨ä½¿ç”¨Whisper APIè¯†åˆ«è¯­éŸ³...")
            self.usage_stats['api_calls'] += 1
            
            # å°†éŸ³é¢‘æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_filename = temp_file.name
                
                # è½¬æ¢éŸ³é¢‘æ ¼å¼
                audio_wav = audio_data.get_wav_data()
                temp_file.write(audio_wav)
            
            # ä½¿ç”¨speech_recognitionçš„whisper APIæ”¯æŒ
            if language:
                result = self.recognizer.recognize_whisper_api(
                    audio_data, 
                    api_key=self.api_key,
                    language=language
                )
            else:
                result = self.recognizer.recognize_whisper_api(
                    audio_data, 
                    api_key=self.api_key
                )
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_filename)
            except:
                pass
            
            if result:
                self.usage_stats['successful_recognitions'] += 1
                print(f"âœ… APIè¯†åˆ«æˆåŠŸ: {result}")
                return result
            else:
                print("âŒ APIè¯†åˆ«ç»“æœä¸ºç©º")
                return None
                
        except Exception as e:
            print(f"âŒ Whisper APIè¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def _recognize_with_local_model(self, audio_data: sr.AudioData, language: Optional[str]) -> Optional[str]:
        """ä½¿ç”¨æœ¬åœ°Whisperæ¨¡å‹è¿›è¡Œè¯†åˆ«"""
        try:
            print(f"ğŸ¤ æ­£åœ¨ä½¿ç”¨Whisperæœ¬åœ°æ¨¡å‹è¯†åˆ«è¯­éŸ³ (æ¨¡å‹: {self.model_size})...")
            self.usage_stats['local_calls'] += 1
            
            # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_wav = audio_data.get_wav_data()
            
            # ä¿å­˜ä¸ºä¸´æ—¶wavæ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_filename = temp_file.name
                temp_file.write(audio_wav)
            
            # ä½¿ç”¨Whisperè¿›è¡Œè½¬å½•
            transcribe_options = {}
            if language:
                transcribe_options['language'] = language
            
            result = self.whisper_model.transcribe(temp_filename, **transcribe_options)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_filename)
            except:
                pass
            
            text = result.get('text', '').strip()
            
            if text:
                self.usage_stats['successful_recognitions'] += 1
                
                # è·å–ç½®ä¿¡åº¦ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                segments = result.get('segments', [])
                if segments:
                    avg_confidence = sum(seg.get('no_speech_prob', 0) for seg in segments) / len(segments)
                    confidence = 1.0 - avg_confidence  # è½¬æ¢ä¸ºç½®ä¿¡åº¦
                    self.usage_stats['avg_confidence'] = (
                        (self.usage_stats['avg_confidence'] * (self.usage_stats['successful_recognitions'] - 1) + confidence) 
                        / self.usage_stats['successful_recognitions']
                    )
                
                # æ˜¾ç¤ºè¯†åˆ«çš„è¯­è¨€ï¼ˆå¦‚æœæ£€æµ‹åˆ°ï¼‰
                detected_language = result.get('language', 'unknown')
                print(f"âœ… æœ¬åœ°è¯†åˆ«æˆåŠŸ (è¯­è¨€: {detected_language}): {text}")
                
                return text
            else:
                print("âŒ æœ¬åœ°è¯†åˆ«ç»“æœä¸ºç©º")
                return None
                
        except Exception as e:
            print(f"âŒ Whisperæœ¬åœ°è¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def get_service_name(self) -> str:
        """è·å–æœåŠ¡åç§°"""
        if self.use_api:
            return f"WhisperAPI"
        else:
            return f"Whisper-{self.model_size}"
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            if self.use_api:
                return bool(self.api_key)
            else:
                return self.whisper_model is not None
        except:
            return False
    
    def get_supported_languages(self) -> list:
        """è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
        # Whisperæ”¯æŒçš„ä¸»è¦è¯­è¨€
        return [
            'zh', 'en', 'es', 'fr', 'de', 'it', 'ja', 'ko', 'ru', 'pt', 
            'ar', 'hi', 'th', 'vi', 'tr', 'pl', 'nl', 'sv', 'da', 'no'
        ]
    
    def test_recognition(self) -> bool:
        """
        æµ‹è¯•è¯†åˆ«åŠŸèƒ½
        
        Returns:
            æ˜¯å¦æµ‹è¯•æˆåŠŸ
        """
        try:
            print("ğŸ§ª æµ‹è¯•Whisperè¯†åˆ«åŠŸèƒ½...")
            with self.microphone as source:
                print("è¯·è¯´ä¸€å¥è¯è¿›è¡Œæµ‹è¯•ï¼ˆ5ç§’å†…ï¼‰...")
                audio = self.recognizer.listen(source, timeout=5, phrase_time_limit=3)
                
                result = self.recognize_auto(audio)
                if result:
                    print(f"âœ… Whisperè¯†åˆ«æµ‹è¯•æˆåŠŸ: {result}")
                    return True
                else:
                    print("âŒ Whisperè¯†åˆ«æµ‹è¯•å¤±è´¥: æ— è¯†åˆ«ç»“æœ")
                    return False
                    
        except sr.WaitTimeoutError:
            print("âš ï¸ æµ‹è¯•è¶…æ—¶ï¼Œæœªæ£€æµ‹åˆ°è¯­éŸ³")
            return False
        except Exception as e:
            print(f"âŒ Whisperè¯†åˆ«æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def print_service_info(self):
        """æ‰“å°æœåŠ¡ä¿¡æ¯"""
        print(f"\nğŸ¤ Whisper ASRæœåŠ¡ä¿¡æ¯:")
        print(f"   æœåŠ¡åç§°: {self.get_service_name()}")
        print(f"   è¿è¡Œæ¨¡å¼: {'APIæ¨¡å¼' if self.use_api else 'æœ¬åœ°æ¨¡å¼'}")
        
        if not self.use_api:
            print(f"   æ¨¡å‹å¤§å°: {self.model_size}")
            print(f"   è®¾å¤‡: {self.device}")
        
        print(f"   é»˜è®¤è¯­è¨€: {self.language}")
        print(f"   æ”¯æŒè¯­è¨€: {', '.join(self.get_supported_languages()[:10])}...")
        print(f"   æœåŠ¡çŠ¶æ€: {'âœ… å¯ç”¨' if self.is_available() else 'âŒ ä¸å¯ç”¨'}")
    
    def print_usage_stats(self):
        """æ‰“å°ä½¿ç”¨ç»Ÿè®¡"""
        print(f"\nğŸ“Š Whisper ASRä½¿ç”¨ç»Ÿè®¡:")
        print(f"   æ€»è¯†åˆ«æ¬¡æ•°: {self.usage_stats['total_recognitions']}")
        print(f"   æˆåŠŸè¯†åˆ«æ¬¡æ•°: {self.usage_stats['successful_recognitions']}")
        
        if self.usage_stats['total_recognitions'] > 0:
            success_rate = (self.usage_stats['successful_recognitions'] / 
                          self.usage_stats['total_recognitions']) * 100
            print(f"   è¯†åˆ«æˆåŠŸç‡: {success_rate:.1f}%")
        
        if self.use_api:
            print(f"   APIè°ƒç”¨æ¬¡æ•°: {self.usage_stats['api_calls']}")
        else:
            print(f"   æœ¬åœ°è°ƒç”¨æ¬¡æ•°: {self.usage_stats['local_calls']}")
            
        if self.usage_stats['avg_confidence'] > 0:
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {self.usage_stats['avg_confidence']:.2f}")
    
    # å…¼å®¹åŸASRServiceæ¥å£çš„æ–¹æ³•
    def set_energy_threshold(self, threshold: float):
        """è®¾ç½®èƒ½é‡é˜ˆå€¼"""
        self.recognizer.energy_threshold = threshold
        print(f"ğŸ”§ èƒ½é‡é˜ˆå€¼è®¾ç½®ä¸º: {threshold}")
    
    def get_energy_threshold(self) -> float:
        """è·å–å½“å‰èƒ½é‡é˜ˆå€¼"""
        return self.recognizer.energy_threshold
    
    def adjust_energy_threshold_multiplier(self, multiplier: float = None):
        """è°ƒæ•´èƒ½é‡é˜ˆå€¼å€æ•°"""
        if multiplier is None:
            multiplier = self.config.get_float('VOICE_DETECTION', 'energy_threshold_multiplier', 1.5)
        
        current_threshold = self.recognizer.energy_threshold
        new_threshold = current_threshold * multiplier
        self.recognizer.energy_threshold = new_threshold
        
        print(f"ğŸ”§ èƒ½é‡é˜ˆå€¼ä» {current_threshold:.0f} è°ƒæ•´ä¸º {new_threshold:.0f}")
    
    def test_microphone(self) -> bool:
        """æµ‹è¯•éº¦å…‹é£æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
        try:
            print("ğŸ¤ æµ‹è¯•éº¦å…‹é£...")
            with self.microphone as source:
                print("è¯·è¯´è¯è¿›è¡Œæµ‹è¯•...")
                audio = self.recognizer.listen(source, timeout=3, phrase_time_limit=2)
                print("âœ… éº¦å…‹é£æµ‹è¯•æˆåŠŸ")
                return True
        except sr.WaitTimeoutError:
            print("âš ï¸ éº¦å…‹é£æµ‹è¯•è¶…æ—¶ï¼Œå¯èƒ½æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³")
            return False
        except Exception as e:
            print(f"âŒ éº¦å…‹é£æµ‹è¯•å¤±è´¥ï¼š{e}")
            return False
    
    def calibrate_for_ambient_noise(self, duration: float = 2.0):
        """é‡æ–°æ ¡å‡†ç¯å¢ƒå™ªéŸ³"""
        print(f"ğŸ”§ é‡æ–°æ ¡å‡†ç¯å¢ƒå™ªéŸ³ï¼ˆæŒç»­{duration}ç§’ï¼‰...")
        try:
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=duration)
            print(f"âœ… ç¯å¢ƒå™ªéŸ³æ ¡å‡†å®Œæˆï¼Œæ–°é˜ˆå€¼: {self.recognizer.energy_threshold:.0f}")
        except Exception as e:
            print(f"âŒ ç¯å¢ƒå™ªéŸ³æ ¡å‡†å¤±è´¥ï¼š{e}") 